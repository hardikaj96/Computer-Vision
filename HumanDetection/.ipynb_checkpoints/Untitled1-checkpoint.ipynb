{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "def getImagePathsWithOutput(path_dir_output):\n",
    "    image_paths = []\n",
    "    output = []\n",
    "    for folder in path_dir_output.keys():\n",
    "        for dirt, subdirt, fileList in os.walk(folder):\n",
    "            for file in fileList:\n",
    "                image_paths.append(folder + file)\n",
    "                output.append(path_dir_output[folder])\n",
    "    return image_paths, output\n",
    "\n",
    "class HOGFeature:\n",
    "    \n",
    "    def rgb2gray(self, img):\n",
    "        '''\n",
    "        function to convert image from color image to grayscale image\n",
    "        img = the image matrix\n",
    "        '''\n",
    "        gray = np.zeros((img.shape[0],img.shape[1]))\n",
    "        for i in range(0,img.shape[0]):\n",
    "            for j in range(0,img.shape[1]):\n",
    "                bgr = img[i,j]\n",
    "                b = bgr[0]\n",
    "                g = bgr[1]\n",
    "                r = bgr[2]\n",
    "                gray[i,j] = round(0.299*r+0.587*g+0.114*b)\n",
    "        return gray\n",
    "    \n",
    "    def apply_sobel(self, img):\n",
    "        '''\n",
    "        Function to compute Normalized Gradient Magnitude and Gradient Angle\n",
    "        '''\n",
    "        #Sobel Filter Mask to calculate Horizontal(x) gradient\n",
    "        sobel_x = (1/4)*np.array([(-1,0,1),\n",
    "                    (-2,0,2),\n",
    "                    (-1,0,1)])\n",
    "        #Sobel Filter Mask to calculate Vertical(y) gradient\n",
    "        sobel_y = (1/4)*np.array([(1,2,1),\n",
    "                    (0,0,0),\n",
    "                    (-1,-2,-1)])\n",
    "\n",
    "        #initialize matrices to store the value of horizontal and vertical gradient,\n",
    "        #normalized horizontal and vertical gradient, normalized gradient magnitude\n",
    "        #and gradient angle\n",
    "        gradient_magnitude = np.zeros(shape=img.shape)\n",
    "        gradient_angle = np.zeros(shape=img.shape)\n",
    "        #find the gradient values by perfoeming convolution\n",
    "        for row in range(0,img.shape[0]-2):\n",
    "            for col in range(0,img[row].size-2):\n",
    "                #calculate Value at current pixel (row,col) \n",
    "                #after applying sobel operator\n",
    "                gx, gy = 0, 0\n",
    "                for i in range (0,3):\n",
    "                    for j in range (0,3):\n",
    "                        gx = gx + img[row+i][col+j] * sobel_x[i][j]\n",
    "                        gy = gy + img[row+i][col+j] * sobel_y[i][j]\n",
    "                #normalize gradient magnitude by dividing by sqrt(2)\n",
    "                gradient_magnitude[row+1][col+1]=((gx**2+gy**2)**(0.5))/(1.4142)\n",
    "                #calculate gradient angle based on sobel horizontal gradient and vertical gradient\n",
    "                angle = 0\n",
    "                if(gx == 0):\n",
    "                    if( gy > 0):\n",
    "                        angle = 90\n",
    "                    else:\n",
    "                        angle = -90\n",
    "                else:\n",
    "                    angle = math.degrees(math.atan(gy/gx))\n",
    "                if (angle < 0):\n",
    "                    angle = angle + 180\n",
    "                gradient_angle[row+1,col+1]  = angle\n",
    "        return [gradient_magnitude, gradient_angle]\n",
    "    \n",
    "    def get_cell_histogram(self, gradient_magnitude, gradient_angle):\n",
    "        '''\n",
    "        This function is to get histogram for each 8x8 cell\n",
    "        gradient_magnitude = gradient magnitude for each pixel\n",
    "        gradient_angle = gradient angle for each pixel\n",
    "        '''\n",
    "        cell_shape = gradient_magnitude.shape\n",
    "        #initialize the number of cell rows and cell columns\n",
    "        cell_rows = round(cell_shape[0]/8)\n",
    "        cell_cols = round(cell_shape[1]/8)\n",
    "        histogram_cell = np.zeros((cell_rows,cell_cols,9))\n",
    "        for r in range (0,cell_rows-1):\n",
    "            for c in range (0,cell_cols-1):\n",
    "                for row in range (r*8,r*8+8):\n",
    "                    for col in range (c*8,c*8+8):\n",
    "                        angle = gradient_angle[row][col]\n",
    "                        grad_mag = gradient_magnitude[row][col]\n",
    "                        if angle%20 == 0:\n",
    "                            if angle == 180:\n",
    "                                histogram_cell[r][c][0] += grad_mag\n",
    "                                continue\n",
    "                            bin_no = int(angle/20)\n",
    "                            histogram_cell[r][c][bin_no] += grad_mag\n",
    "                            continue\n",
    "                        bin_no_l = int(angle/20)\n",
    "                        #calculate the vote for left and right bins.\n",
    "                        if bin_no_l < 8:\n",
    "                            bin_no_r = bin_no_l + 1\n",
    "                            histogram_cell[r][c][bin_no_r] += grad_mag*((angle - (bin_no_l * 20))/20)\n",
    "                            histogram_cell[r][c][bin_no_l] += grad_mag*(((bin_no_r * 20) - angle)/20)\n",
    "                        else:\n",
    "                            bin_no_r = 0\n",
    "                            histogram_cell[r][c][bin_no_r] += grad_mag*((angle - 160)/20)\n",
    "                            histogram_cell[r][c][bin_no_l] += grad_mag*((180 - angle)/20)\n",
    "        squared_histogram_cell = np.square(histogram_cell)\n",
    "        return [histogram_cell, squared_histogram_cell] \n",
    " \n",
    "    \n",
    "    def get_hog_descriptor(self, histogram_cell, histogram_cell_squared):\n",
    "        cell_histogram_shape = histogram_cell.shape\n",
    "        descriptor = np.array([])\n",
    "        for row in range(0,cell_histogram_shape[0]-1):\n",
    "            for col in range(0,cell_histogram_shape[1]-1):\n",
    "                block = np.array([])\n",
    "                block_squared = np.array([])\n",
    "                block = np.append(block,histogram_cell[row,col])\n",
    "                block = np.append(block,histogram_cell[row,col+1])\n",
    "                block = np.append(block,histogram_cell[row+1,col])\n",
    "                block = np.append(block,histogram_cell[row+1,col+1])\n",
    "                block_squared = np.append(block_squared,histogram_cell_squared[row,col])\n",
    "                block_squared = np.append(block_squared,histogram_cell_squared[row,col+1])\n",
    "                block_squared = np.append(block_squared,histogram_cell_squared[row+1,col])\n",
    "                block_squared = np.append(block_squared,histogram_cell_squared[row+1,col+1])\n",
    "                block_squared = np.sum(block_squared)\n",
    "                if(block_squared>0):\n",
    "                    #normalize the block descriptor\n",
    "                    normalized = np.sqrt(block_squared)\n",
    "                    block = (1/normalized)*block\n",
    "                descriptor = np.append(descriptor, block)\n",
    "        return descriptor\n",
    "\n",
    "    \n",
    "    def get_LBP_descriptor(self, magnitude):\n",
    "        '''\n",
    "        This function is to get histogram for each 8x8 cell\n",
    "        gradient_magnitude = gradient magnitude for each pixel\n",
    "        gradient_angle = gradient angle for each pixel\n",
    "        '''\n",
    "        pattern = [(-1, -1),(-1, 0),(-1, 1),(0, -1),(0, 1),(1, -1),(1, 0),(1, 1)]\n",
    "        uniform_patterns = np.array([0, 1, 2, 3, 4, 6, 7, 8, 12, 14, 15, 16, 24, 28, 30, 31, 32, 48, 56,\n",
    "        60, 62, 63, 64, 96, 112, 120, 124, 126, 127, 128, 129, 131, 135, 143, 159, 191, 192, 193, 195, 199,\n",
    "        207, 223, 224, 225, 227, 231, 239, 240, 241, 243, 247, 248, 249, 251, 252, 253, 254, 255])\n",
    "        non_uniform_patterns = np.array(list(set(np.arange(256))-set(uniform_patterns)))\n",
    "        cell_shape = magnitude.shape\n",
    "        #initialize the number of cell rows and cell columns\n",
    "        cell_rows = round(cell_shape[0]/16)\n",
    "        cell_cols = round(cell_shape[1]/16)\n",
    "        histogram_block = np.zeros((cell_rows,cell_cols,59))\n",
    "        lbp_mask = np.zeros(magnitude.shape)\n",
    "        lbp_descriptor = np.array([])\n",
    "        for r in range (0,cell_rows):\n",
    "            for c in range (0,cell_cols):\n",
    "                histogram_block = np.zeros(256)\n",
    "                for row in range (r*16,r*16+16):\n",
    "                    for col in range (c*16,c*16+16):\n",
    "                        if row == 0 or col == 0 or row == magnitude.shape[0]-1 or col == magnitude.shape[1]-1:\n",
    "                            lbp_mask[row][col] = 5\n",
    "                            continue\n",
    "                        bin_val = ''\n",
    "                        mag = magnitude[row][col]\n",
    "                        for i,j in pattern:\n",
    "                            if magnitude[row+i][col+j] >= mag:\n",
    "                                bin_val += '1'\n",
    "                            else:\n",
    "                                bin_val += '0'\n",
    "                        histogram_block[int(bin_val,2)] += 1\n",
    "                normalized_histogram = histogram_block/256\n",
    "                bin_59 = sum(normalized_histogram[non_uniform_patterns])\n",
    "                bin_1_58 = normalized_histogram[uniform_patterns]\n",
    "                bin_1_59 = np.append(bin_1_58, bin_59)\n",
    "                lbp_descriptor = np.append(lbp_descriptor,bin_1_59)\n",
    "        return lbp_descriptor\n",
    "    \n",
    "    \n",
    "    def saveImageAndHog(self, mag, hog, lbp, path):\n",
    "        \"\"\"\n",
    "        function to save the image and hog descriptor\n",
    "        \"\"\"\n",
    "        pathSplit = path.split('/')\n",
    "        currImage = pathSplit[-1]\n",
    "        imageName, imageExt = currImage.split('.')\n",
    "        updatedImage = '.'.join([imageName+'_mag',imageExt])\n",
    "        imageFolder = '/'.join(pathSplit[:-1])\n",
    "        imageFolder += \"_res\"\n",
    "        if not os.path.exists(imageFolder):\n",
    "            os.makedirs(imageFolder)\n",
    "        finalPath = '/'.join([imageFolder,updatedImage])\n",
    "        cv2.imwrite(finalPath, mag)\n",
    "        filename = imageFolder+\"/\"+imageName+\"_hog.txt\"\n",
    "        hog_file = open(filename,'a+')\n",
    "        for i in hog:\n",
    "            hog_file.write(str(i[0])+'\\n')\n",
    "        hog_file.close()\n",
    "        filename = imageFolder+\"/\"+imageName+\"_lbp.txt\"\n",
    "        lbp_file = open(filename,'a+')\n",
    "        for i in lbp:\n",
    "            lbp_file.write(str(i[0])+'\\n')\n",
    "        lbp_file.close()\n",
    "        \n",
    "    def HogLbp(self, image_list):\n",
    "        hog_features = []\n",
    "        lbp_features = []\n",
    "        for image in image_list:\n",
    "            color_img = cv2.imread(image,cv2.IMREAD_COLOR)\n",
    "            gray_img = self.rgb2gray(color_img)\n",
    "            gradient_magnitude, gradient_angle = self.apply_sobel(gray_img)\n",
    "            histogram = self.get_cell_histogram(gradient_magnitude, gradient_angle)\n",
    "            histogram_cell = histogram[0]\n",
    "            squared_histogram_cell = histogram[1]\n",
    "            HOG_descriptor = self.get_hog_descriptor(histogram_cell, squared_histogram_cell)\n",
    "            HOG_descriptor = HOG_descriptor.reshape(-1,1)\n",
    "            LBP_descriptor = self.get_LBP_descriptor(gradient_magnitude)\n",
    "            LBP_descriptor = LBP_descriptor.reshape(-1,1)\n",
    "            self.saveImageAndHog(gradient_magnitude, HOG_descriptor, LBP_descriptor, image)\n",
    "            hog_features.append(HOG_descriptor)\n",
    "            lbp_features.append(LBP_descriptor)\n",
    "        return hog_features,lbp_features\n",
    "\n",
    "def ReLU(x):\n",
    "    \"\"\"Function to calculate RELU\n",
    "    \"\"\"\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            if x[i,j]<0:\n",
    "                x[i,j]=0\n",
    "    return x\n",
    "\n",
    "def Sigmoid(x):\n",
    "    \"\"\"\n",
    "    Function to calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def neural_network(network,out,hidden):\n",
    "    \"\"\"\n",
    "    Function to implament neural network, to train it.\n",
    "    \"\"\"\n",
    "    aplha = 0.1                                               \n",
    "    # Initializing the learning rate\n",
    "    total_hidden = network.shape[1]                                         \n",
    "    total_output = network.shape[2]\n",
    "    # Initializing and Factoring the weight for hidden layer\n",
    "    w1 = np.random.randn(total_hidden,hidden)                          \n",
    "    w1 = np.multiply(w1,math.sqrt(2/int(total_hidden+hidden)))\n",
    "    # Initializing and Factoring the weight for output layer         \n",
    "    w2 = np.random.randn(hidden,total_output)\n",
    "    w2 = np.multiply(w2,math.sqrt(2/int(hidden+total_output)))\n",
    "    # Bias for hidden and output layer\n",
    "    b1 = np.random.randn(hidden)                         \n",
    "    b1 = np.multiply(b1,math.sqrt(2/int(hidden)))\n",
    "    b2 = np.random.randn(total_output)\n",
    "    b2 = np.multiply(b2,math.sqrt(2/int(total_output)))\n",
    "    epoch = 0\n",
    "    err_sq = 0\n",
    "    prev_err = sys.maxsize\n",
    "    while True:                                         \n",
    "        # FeedForward and Backpropagation for each epoch of all vectors\n",
    "        for i in range(network.shape[0]):\n",
    "            x = network[i,:].reshape([1,-1])                     \n",
    "            # Computing values for hidden layer and output layer in feedforward\n",
    "            layer1_output = ReLU((x.dot(w1)+b1))\n",
    "            layer2_output = Sigmoid((layer1_output.dot(w2)+b2))\n",
    "            err = out[i]-layer2_output           \n",
    "            err_sq += 0.5*err*err\n",
    "            #Doing BackPropagation\n",
    "            del_output = (-1*err)*(1-layer2_output)*layer2_output                         \n",
    "            del_layer2 = layer1_output.T.dot(del_output)\n",
    "            del_bias_layer2 = np.sum(del_output,axis = 0)\n",
    "            layer1_output_like = np.zeros_like(layer1_output)\n",
    "            for k in range(hidden):\n",
    "                if(layer1_output[0][k]>0):\n",
    "                    layer1_output_like[0][k] = 1\n",
    "                else:\n",
    "                    layer1_output_like[0][k] = 0                       \n",
    "            del_hidden = del_output.dot(w2.T)*layer1_output_like\n",
    "            del_layer1 = x.T.dot(del_hidden)\n",
    "            del_bias_layer1 = np.sum(del_hidden,axis=0)\n",
    "\n",
    "            w2 -= aplha*del_layer2\n",
    "            b2 -= aplha*del_bias_layer2\n",
    "            w1 -= aplha*del_layer1\n",
    "            b1 -= aplha*del_bias_layer1\n",
    "        ep_err = np.mean(err_sq)/network.shape[0]\n",
    "        print(\"Epoch Count: \" + str(epoch), \"Average Error: \", ep_err)\n",
    "        if(ep_err < prev_err):\n",
    "            print(\"error decreased by \", prev_err-ep_err)\n",
    "        else:\n",
    "            if(ep_err > prev_err):\n",
    "                print(\"error increased by \", ep_err-prev_err)\n",
    "            else:\n",
    "                print(\"error stayed same\")\n",
    "        #check for the change in error if very less we can stop training\n",
    "        if(abs(prev_err - ep_err) < 0.0001):\n",
    "            print(\"training complete....\")\n",
    "            break\n",
    "        prev_err = ep_err\n",
    "        epoch += 1\n",
    "\n",
    "    return w1,b1,w2,b2\n",
    "\n",
    "def predict(w,wb,v,vb,output_descriptor):\n",
    "    # Function to predict values for my neural network\n",
    "    number_of_test_image,number_of_attribute=output_descriptor.shape\n",
    "    predict=[]\n",
    "    for k in range(number_of_test_image):\n",
    "            x=output_descriptor[k,:].reshape([1,-1])\n",
    "            z=ReLU((x.dot(w)+wb))\n",
    "            y=Sigmoid(z.dot(v)+vb)\n",
    "            predict.append(y)\n",
    "    return predict\n",
    "\n",
    "\n",
    "if __name__ == '__main__'\n",
    "    root = 'ImageData/' \n",
    "    train_pos_dir = root + 'Training_images_Pos/'\n",
    "    train_neg_dir = root + 'Training_images_Neg/' \n",
    "    test_pos_dir = root + 'Test_images_Pos/' \n",
    "    test_neg_dir = root + 'Test_images_Neg/' \n",
    "\n",
    "    train_data_dir_with_output = {\n",
    "        train_pos_dir:1,\n",
    "        train_neg_dir:0\n",
    "    }\n",
    "    test_data_dir_with_output = {\n",
    "        test_neg_dir:0,\n",
    "        test_pos_dir:1\n",
    "    }\n",
    "\n",
    "    training_image_paths, training_output = getImagePathsWithOutput(train_data_dir_with_output)\n",
    "    testing_image_paths, testing_output = getImagePathsWithOutput(test_data_dir_with_output)\n",
    "\n",
    "    h = HOGFeature()\n",
    "\n",
    "    hog_train, lbp_train = h.HogLbp(training_image_paths)\n",
    "\n",
    "    hog_test, lbp_test = h.HogLbp(testing_image_paths)\n",
    "\n",
    "    hog_lbp_train = []\n",
    "    for i,j in zip(hog_train, lbp_train):\n",
    "        hog_lbp_train.append(np.append(i,j))\n",
    "\n",
    "    hog_lbp_test = []\n",
    "    for i,j in zip(hog_test, lbp_test):\n",
    "        hog_lbp_test.append(np.append(i,j))\n",
    "\n",
    "    train_data_hog = np.array(hog_train)\n",
    "    test_data_hog = np.array(hog_test)\n",
    "\n",
    "\n",
    "    train_data_hoglbp = np.array(hog_lbp_train).reshape(20,11064,1)\n",
    "    test_data_hoglbp = np.array(hog_lbp_test).reshape(10,11064,1)\n",
    "    \n",
    "    print('\\n\\HOG only ')\n",
    "    for hidden in [200,400]:\n",
    "        print('\\n\\nHIDDEN LAYER = %d \\n\\n'%(hidden))\n",
    "        w1,w1bias,w2,w2bias = neural_network(np.array(hog_train),np.array(training_output),hidden)\n",
    "        predicted_output = predict(w1,w1bias,w2,w2bias,np.array(hog_test).reshape(10,7524))\n",
    "        prediction = []\n",
    "        classes = []\n",
    "        for predicted in predicted_output:\n",
    "            if(predicted >=0.5):\n",
    "                prediction.append(1)\n",
    "            else:\n",
    "                prediction.append(0)\n",
    "            if predicted >= 0.6:\n",
    "                classes.append('human')\n",
    "            elif predicted <= 0.4:\n",
    "                classes.append('no-human')\n",
    "            else:\n",
    "                classes.append('borderline')\n",
    "\n",
    "        correct=0\n",
    "        wrong=0\n",
    "        error = 0\n",
    "        for i in range(len(prediction)):\n",
    "            error += abs(testing_output[i] - predicted_output[i])\n",
    "            if(prediction[i]==testing_output[i]):\n",
    "                correct+=1\n",
    "            else:\n",
    "                wrong+=1\n",
    "            print(testing_image_paths[i] + ' = class (' + classes[i] + ') with predicted value as  :: ' + str(predicted_output[i][0][0]))\n",
    "        print('correct = %d'%(correct))\n",
    "        print('wrong = %d'%(wrong))\n",
    "        print('average error = %d'%(error/10))\n",
    "        print(predicted_output)\n",
    "        print(testing_output)\n",
    "\n",
    "    \n",
    "    print('\\n\\HOG and LBP ')\n",
    "    for hidden in [200,400]:\n",
    "        print('\\n\\nHIDDEN LAYER = %d \\n\\n'%(hidden))\n",
    "        w1,w1bias,w2,w2bias = neural_network(train_data_hoglbp,np.array(training_output),hidden)\n",
    "        predicted_output=predict(w1,w1bias,w2,w2bias,test_data_hoglbp.reshape(10,11064))\n",
    "        prediction = []\n",
    "        classes = []\n",
    "        for predicted in predicted_output:\n",
    "            if(predicted >=0.5):\n",
    "                prediction.append(1)\n",
    "            else:\n",
    "                prediction.append(0)\n",
    "            if predicted >= 0.6:\n",
    "                classes.append('human')\n",
    "            elif predicted <= 0.4:\n",
    "                classes.append('no-human')\n",
    "            else:\n",
    "                classes.append('borderline')\n",
    "\n",
    "        correct=0\n",
    "        wrong=0\n",
    "        error = 0\n",
    "        for i in range(len(prediction)):\n",
    "            error += abs(testing_output[i] - predicted_output[i])\n",
    "            if(prediction[i]==testing_output[i]):\n",
    "                correct+=1\n",
    "            else:\n",
    "                wrong+=1\n",
    "            print(testing_image_paths[i] + ' = class (' + classes[i] + ') with predicted value as  :: ' + str(predicted_output[i][0][0]))\n",
    "        print('correct = %d'%(correct))\n",
    "        print('wrong = %d'%(wrong))\n",
    "        print('average error = %d'%(error/10))\n",
    "        print(predicted_output)\n",
    "        print(testing_output)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
